# -*- coding: utf-8 -*-
"""PDI_TP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BjtiZ6KN2_hzJxeHrrF1yhH958CkO7R0

# Grupo:
*   Pablo Martins Coelho
*   Paulo Corrêa
*   Pedro Henrique Oliveira

# IMPORTAÇÃO DAS BIBLIOTECAS E DOWNLOAD DA BASE DE DADOS
"""

import numpy as np
from skimage.util import view_as_blocks
from skimage.feature import hog
from skimage import io, color, img_as_float
from sklearn import svm, metrics, preprocessing
import matplotlib.pyplot as plt
import skimage
import dlib
import cv2
import re
from google.colab.patches import cv2_imshow
from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score

import zipfile
import os

local_zip = 'archive.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('tmp')
zip_ref.close()

"""# FUNCOES UTILIZADAS"""

def compute_eer(label, pred, positive_label=1):
    # all fpr, tpr, fnr, fnr, threshold are lists (in the format of np.array)
    fpr, tpr, threshold = metrics.roc_curve(label, pred, pos_label= positive_label)
    fnr = 1 - tpr

    # the threshold of fnr == fpr
    eer_threshold = threshold[np.nanargmin(np.absolute((fnr - fpr)))]

    # theoretically eer from fpr and eer from fnr should be identical but they can be slightly differ in reality
    eer_1 = fpr[np.nanargmin(np.absolute((fnr - fpr)))]
    eer_2 = fnr[np.nanargmin(np.absolute((fnr - fpr)))]

    # return the mean of eer from fpr and from fnr
    eer = (eer_1 + eer_2) / 2
    return eer

TRAIN_PATH = 'tmp/train_img/train_img/color/'
TEST_PATH = 'tmp/test_img/test_img/color/'

def _entropy(hist):
    #hist = hist[hist != 0]
    return -np.sum(hist * np.log2(hist+1e-7))

def n_EBHOG(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(3, 3)):
    cx, cy = pixels_per_cell
    bx, by = cells_per_block
    gx = image.shape[1] // cx
    gy = image.shape[0] // cy
    
    bs = bx * by * orientations
    hog_feats = hog(image, orientations=orientations, pixels_per_cell=pixels_per_cell,
                    cells_per_block=cells_per_block, feature_vector=False)
    ebhog = np.zeros((gy - by + 1, gx - bx + 1, bs), dtype=float)
    entropies = []

    
    for x in range(gx - bx + 1):
        for y in range(gy - by + 1):
            block = image[(cx*x):(cx*x) + bx*cx, cy*y: (cy*y)+by*cy]
            entropy = _entropy(block)
            entropies.append(entropy)
            ebhog[x, y, :] = hog_feats[x, y].ravel()
    entropies = np.array(entropies)
    w = np.zeros((gy - by + 1, gx - bx + 1), dtype=float)
    H_max = np.max(entropies)
    H_min = np.min(entropies)
    for x in range(gx - bx + 1):
        for y in range(gy - by + 1):
            entropy = entropies[y * (gx - bx + 1) + x]
            w[y, x] = H_max * ((entropy - H_min) / (H_max - H_min))
    w = np.reshape(w, (gy - by + 1, gx - bx + 1,1))
    ebhog_weighted = ebhog * w
    max_k = np.max(ebhog_weighted)
    min_k = np.min(ebhog_weighted)
    ebhog_norm = (ebhog_weighted) / (max_k - min_k)

    return ebhog_norm.ravel()

def _entropy(hist):
    hist = hist[hist != 0]
    return -np.sum(hist * np.log2(hist+1e-7))

def EBHOG(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(3, 3)):
    cx, cy = pixels_per_cell
    bx, by = cells_per_block
    gx = image.shape[1] // cx
    gy = image.shape[0] // cy
    
    bs = bx * by * orientations
    hog_feats = hog(image, orientations=orientations, pixels_per_cell=pixels_per_cell,
                    cells_per_block=cells_per_block, feature_vector=False)
    ebhog = np.zeros((gy - by + 1, gx - bx + 1, bs), dtype=float)
    entropies = []


    for x in range(gx - bx + 1):
        for y in range(gy - by + 1):
            block = hog_feats[y, x, :]
            block = block.ravel()
            entropy = _entropy(block)
            entropies.append(entropy)
            ebhog[y, x, :] = block
    entropies = np.array(entropies)
    w = np.zeros((gy - by + 1, gx - bx + 1, bs), dtype=float)
    H_max = np.max(entropies)
    H_min = np.min(entropies)
    for x in range(gx - bx + 1):
        for y in range(gy - by + 1):
            entropy = entropies[y * (gx - bx + 1) + x]
            w[y, x, :] = H_max * ((entropy - H_min) / (H_max - H_min))
    ebhog_weighted = ebhog * w
    max_k = np.max(ebhog_weighted)
    min_k = np.min(ebhog_weighted)
    ebhog_norm = (ebhog_weighted) / (max_k - min_k)
    return ebhog_norm.ravel()

def preprocessing_images(path, mode = "HOG"):
  img_files = os.listdir(path)
  detector = dlib.get_frontal_face_detector()
  n = len(img_files)
  x_set = np.zeros((n,2048))
  y_set = np.zeros((n))
  for i in range(len(img_files)):

    if(re.search('real', img_files[i]) == None):
      y_set[i] = 1    #ROTULO 1 EH IMG FALSA, FACE SPOOFING
    else:
      y_set[i] = 0    #ROTULO 0 EH IMG REAL, ROSTO REAL DE PESSOA


    img = cv2.imread(path + img_files[i])
    
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)


    faces = detector(gray)

    for face in faces:
        x, y = face.left(), face.top()
        x2, y2 = face.right(), face.bottom()
        nimg = gray[y:y2, x:x2]

    n2img = cv2.resize(nimg, (256,256), interpolation = cv2.INTER_LINEAR)
    n3img = img_as_float(n2img)
    if(mode == "HOG"):
      hog_features = hog(n3img, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1))
      x_set[i] = hog_features
      print(i+1, " de ", n)
    
    elif(mode == "EBHOG"):
      ebhog_features = EBHOG(n3img, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1))
      print(i+1, " de ", n)
      x_set[i] = ebhog_features

    else:
      ebhog_features = n_EBHOG(n3img, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1))
      print(i+1, " de ", n)
      x_set[i] = ebhog_features
  
  
  return x_set, y_set

"""# Treino com o descritor HOG

Treinando Modelo
"""

x_train, y_train = preprocessing_images(TRAIN_PATH)
std_scaler = preprocessing.StandardScaler().fit(x_train)
x_train_Xp = std_scaler.transform(x_train)

h_model = svm.SVC(kernel='linear', C=2.0)

h_model.fit(x_train_Xp, y_train)

"""Predição"""

x_test, y_test = preprocessing_images(TEST_PATH)
std_scaler = preprocessing.StandardScaler().fit(x_test)
x_test_Xp = std_scaler.transform(x_test)
pred = h_model.predict(x_test_Xp)

"""Analise de resultados"""

h_matriz =  metrics.confusion_matrix(y_test, pred)
disp = metrics.ConfusionMatrixDisplay(confusion_matrix=h_matriz)
disp.plot()
EERhog = compute_eer(y_test, pred)

"""# Treino com descritor EBHOG calculando entropia pelos HOG's da imagem

Treinando modelo
"""

x_train, y_train = preprocessing_images(TRAIN_PATH, mode="EBHOG")
std_scaler = preprocessing.StandardScaler().fit(x_train)
x_train_Xp = std_scaler.transform(x_train)

eh_model = svm.SVC(kernel='linear', C=2.0)

eh_model.fit(x_train_Xp, y_train)

"""Predição"""

x_test, y_test = preprocessing_images(TEST_PATH, mode="EBHOG")
std_scaler = preprocessing.StandardScaler().fit(x_test)
x_test_Xp = std_scaler.transform(x_test)
pred = eh_model.predict(x_test_Xp)

"""Analise de resultados"""

eh_matriz =  metrics.confusion_matrix(y_test, pred)
disp = metrics.ConfusionMatrixDisplay(confusion_matrix=eh_matriz)
disp.plot()
EERebhog = compute_eer(y_test, pred)

"""# Treino com descritor EBHOG calculando entropia pelos batches da imagem

Treinando modelo
"""

x_train, y_train = preprocessing_images(TRAIN_PATH, mode="NEBHOG")
std_scaler = preprocessing.StandardScaler().fit(x_train)
x_train_Xp = std_scaler.transform(x_train)

eh_model = svm.SVC(kernel='linear', C=2.0)

eh_model.fit(x_train_Xp, y_train)

"""Predição"""

x_test, y_test = preprocessing_images(TEST_PATH, mode="NEBHOG")
std_scaler = preprocessing.StandardScaler().fit(x_test)
x_test_Xp = std_scaler.transform(x_test)
pred = eh_model.predict(x_test_Xp)

"""Analise de resultados"""

neh_matriz =  metrics.confusion_matrix(y_test, pred)
disp = metrics.ConfusionMatrixDisplay(confusion_matrix=neh_matriz)
disp.plot()
EERnebhog = compute_eer(y_test, pred)

barwidth = 0.25
r1 = np.arange(4)
r2 = [x + barwidth for x in r1]
r3 = [x + barwidth for x in r2]
plt.bar(r1, h_matriz.flatten(), color = "red", width = barwidth, label="HOG")
plt.bar(r2, eh_matriz.flatten(), color = "green", width = barwidth, label="EBHOG calculando entropia com HOG")
plt.bar(r3, neh_matriz.flatten(), color = "blue", width = barwidth, label="EBHOG calculando entropia com batches da imagem")
plt.xlabel("Methods")
plt.xticks([r + barwidth for r in range(4)], ["True negative", "False positive", "False negative", "True positive"])
plt.ylabel("Num of predict labels")
plt.title("Cell size: 16x16. Block size: 1x1")
plt.legend(bbox_to_anchor = (1.05, 0.6))
plt.show()

print("\t\tEER")
print("HOG = {:.4f} %".format(EERhog*100))
print("EBHOG = {:.4f} %".format(EERebhog*100))
print("NEBHOG = {:.4f} %".format(EERnebhog*100))